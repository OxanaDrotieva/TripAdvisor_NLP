{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a95716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark import SparkContext\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ecb718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SparkConf object\n",
    "conf = SparkConf()\n",
    "# Set the spark.driver.maxResultSize property\n",
    "conf.set(\"spark.driver.maxResultSize\", \"2000m\")  # Adjust the value as needed\n",
    "# Create a SparkSession with the configured SparkConf\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a38f249",
   "metadata": {},
   "outputs": [],
   "source": [
    "NY_reviews = pd.read_csv('./data/New_York_reviews_cleaned.csv', index_col=0)\n",
    "NY_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3060214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NY_reviews_als = NY_reviews[['author_id', 'restaurant_name', 'rating_review', 'date']]\n",
    "NY_reviews_als.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feaf471",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert author_id to numeric\n",
    "## Step 1. convert to numeric\n",
    "pattern = r'^UID_\\d+$'\n",
    "matches = NY_reviews_als['author_id'].str.match(pattern)\n",
    "matches.sum() # make sure all strings have same pattern for easy conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1e5481",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 2. remove prefix\n",
    "NY_reviews_als['author_id_num'] = NY_reviews_als['author_id'].str.replace('UID_', '').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e012605",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert restaurant_name to numeric\n",
    "## Step 1. Create 1-1 indexesmatching restaurant_name\n",
    "NY_reviews_als['restaurant_id'] = pd.factorize(NY_reviews_als['restaurant_name'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54b24f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NY_reviews_als.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae4e087",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check and aggregate multiple reviews by one author for a single restaurant\n",
    "NY_reviews_als['average_rating'] = NY_reviews_als.groupby(['author_id', 'restaurant_id'])['rating_review'].transform('mean')\n",
    "NY_reviews_als_unique = NY_reviews_als.drop_duplicates(subset=['author_id', 'restaurant_id'], keep='first')\n",
    "NY_reviews_als_unique = NY_reviews_als_unique.drop(columns=['rating_review'])\n",
    "NY_reviews_als_unique = NY_reviews_als_unique.rename(columns={'average_rating': 'rating_review'})\n",
    "NY_reviews_als_unique.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd3c909",
   "metadata": {},
   "outputs": [],
   "source": [
    "NY_reviews_als_unique.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1da235",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train / Test split:\n",
    "k = 2 # number of latest reviews / user in Test\n",
    "## Train: part 1 - users with less than k+1 reviews\n",
    "train_1 = NY_reviews_als_unique.groupby(\"author_id\").filter(lambda x: len(x) <= k)\n",
    "\n",
    "## Train: part 2 - users with at least k reviews: all reviews except the latest k reviews\n",
    "users_with_more_than_k_reviews = NY_reviews_als_unique.groupby(\"author_id\").filter(lambda x: len(x) > k)\n",
    "# Sort the DataFrame by 'author_id' and 'date' in descending order\n",
    "users_with_more_than_k_reviews_sorted = users_with_more_than_k_reviews.sort_values(by=['author_id', 'date'], ascending=[True, False])\n",
    "# Get indexes of latest k reviews\n",
    "def get_latest_k_reviews(group):\n",
    "    return group.index[:k]\n",
    "latest_reviews_indexes = users_with_more_than_k_reviews_sorted.groupby('author_id', group_keys=False).apply(get_latest_k_reviews).values\n",
    "latest_reviews_indexes_list = [item for sublist in latest_reviews_indexes for item in sublist]\n",
    "\n",
    "train_2 = users_with_more_than_k_reviews_sorted[~users_with_more_than_k_reviews_sorted.index.isin(latest_reviews_indexes_list)]\n",
    "train = pd.concat([train_1, train_2])          \n",
    "test = users_with_more_than_k_reviews_sorted.loc[latest_reviews_indexes_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dad11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fd73b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158df1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData = spark.createDataFrame(train)\n",
    "TestData = spark.createDataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5b6f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Training\n",
    "# Create ALS model\n",
    "als = ALS(userCol=\"author_id_num\", itemCol=\"restaurant_id\", ratingCol=\"rating_review\", coldStartStrategy=\"drop\")\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(als.rank, [10, 20, 30]) \\\n",
    "    .addGrid(als.maxIter, [10, 20, 30]) \\\n",
    "    .addGrid(als.regParam, [0.5, 0.7, 0.9]) \\\n",
    "    .build()\n",
    "\n",
    "# Define evaluation metric\n",
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol='rating_review', predictionCol='prediction')\n",
    "\n",
    "# Create CrossValidator\n",
    "cross_val = CrossValidator(estimator=als, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=3, collectSubModels=True)\n",
    "\n",
    "# Fit ALS model and tune hyperparameters\n",
    "cv_model = cross_val.fit(TrainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0000045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best ALS model from the CrossValidator\n",
    "best_model = cv_model.bestModel\n",
    "print(\"The best model has rank of \", best_model.rank, \", maxIter of \", best_model._java_obj.parent().getMaxIter(), \" and regParam of \", best_model._java_obj.parent().getRegParam())\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "train_predictions = best_model.transform(TrainData)\n",
    "test_predictions = best_model.transform(TestData)\n",
    "train_rmse = evaluator.evaluate(train_predictions)\n",
    "test_rmse = evaluator.evaluate(test_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data: {:.2f}\".format(test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3b077f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluation\n",
    "# Concordant Rate\n",
    "concordant = 0\n",
    "discordant = 0\n",
    "tie = 0\n",
    "one = []\n",
    "for author in test_predictions_pd[\"author_id\"].unique():\n",
    "    test_author = test_predictions_pd[test_predictions_pd[\"author_id\"] == author]\n",
    "    \n",
    "    if test_author.shape[0] < 2:\n",
    "        one.append(author)\n",
    "        continue\n",
    "    else:\n",
    "        res_1 = test_author.iloc[0]\n",
    "        act_rating_1 = res_1['rating_review']\n",
    "        pred_rating_1 = res_1['prediction']\n",
    "\n",
    "        res_2 = test_author.iloc[1]\n",
    "        act_rating_2 = res_2['rating_review']\n",
    "        pred_rating_2 = res_2['prediction']\n",
    "        if act_rating_1 == act_rating_2:\n",
    "            tie += 1\n",
    "            continue\n",
    "\n",
    "        if (act_rating_1 < act_rating_2) and (pred_rating_1 < pred_rating_2):\n",
    "            concordant += 1\n",
    "        elif (act_rating_1 > act_rating_2) and (pred_rating_1 > pred_rating_2):\n",
    "            concordant += 1\n",
    "        elif (act_rating_1 < act_rating_2) and (pred_rating_1 > pred_rating_2):\n",
    "            discordant += 1\n",
    "        elif (act_rating_1 > act_rating_2) and (pred_rating_1 < pred_rating_2):\n",
    "            discordant += 1\n",
    "\n",
    "print(\"Concordant: \", concordant)\n",
    "print(\"Discordant: \", discordant)\n",
    "print(\"Tie: \", tie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829cd4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluation\n",
    "# Hit Rate\n",
    "user_recs = model.recommendForAllUsers(6)  # Get top 6 recommendations for each user\n",
    "user_recs_pd = user_recs.toPandas()\n",
    "\n",
    "# Define a function to extract the first element from each tuple\n",
    "def extract_first_element(lst_of_tuples):\n",
    "    return [t[0] for t in lst_of_tuples]\n",
    "# Apply the function to the 'old_column' and create the new column\n",
    "user_recs_pd['rec_res'] = user_recs_pd['recommendations'].apply(extract_first_element)\n",
    "\n",
    "# Hit Rate\n",
    "hit = 0\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    recs_author = user_recs_pd[user_recs_pd['author_id_num'] == row['author_id_num']]\n",
    "\n",
    "    if row['restaurant_id'] in recs_author['rec_res']:\n",
    "        recs_author[]\n",
    "        if (row['rating_review'] == 1 or row['rating_review'] == 2):\n",
    "            hit = hit - 1\n",
    "        elif (row['rating_review'] == 4 or row['rating_review'] == 5):\n",
    "            hit = hit + 1\n",
    "\n",
    "print(\"Hit: \", hit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77785d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop SparkSession\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
